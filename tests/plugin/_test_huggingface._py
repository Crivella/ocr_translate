###################################################################################
# ocr_translate - a django app to perform OCR and translation of images.          #
# Copyright (C) 2023-present Davide Grassano                                      #
#                                                                                 #
# This program is free software: you can redistribute it and/or modify            #
# it under the terms of the GNU General Public License as published by            #
# the Free Software Foundation, either version 3 of the License.                  #
#                                                                                 #
# This program is distributed in the hope that it will be useful,                 #
# but WITHOUT ANY WARRANTY; without even the implied warranty of                  #
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                   #
# GNU General Public License for more details.                                    #
#                                                                                 #
# You should have received a copy of the GNU General Public License               #
# along with this program.  If not, see {http://www.gnu.org/licenses/}.           #
#                                                                                 #
# Home: https://github.com/Crivella/ocr_translate                                 #
###################################################################################
"""Test base.py from ocr_tsl."""
# pylint: disable=redefined-outer-name

import importlib
from pathlib import Path

import pytest

from ocr_translate.ocr_tsl import huggingface


@pytest.fixture
def mock_loader():
    """Mock hugging face class with `from_pretrained` method."""
    class Loader():
        """Mocked class."""
        def from_pretrained(self, model_id: Path | str, cache_dir=None):
            """Mocked method."""
            if isinstance(model_id, Path):
                if not model_id.is_dir():
                    raise FileNotFoundError('Not in dir')
            elif isinstance(model_id, str):
                if cache_dir is None:
                    cache_dir = huggingface.root
                if not (cache_dir / f'models--{model_id.replace("/", "--")}').is_dir():
                    raise FileNotFoundError('Not in cache')

    return Loader()

def test_env_transformers_cache(monkeypatch):
    """Test that the TRANSFORMERS_CACHE environment variable is set."""
    monkeypatch.setenv('TRANSFORMERS_CACHE', 'test')
    importlib.reload(huggingface)
    assert huggingface.root == Path('test')

def test_load_from_storage_dir_fail(monkeypatch, mock_loader, tmpdir):
    """Test low-level loading a huggingface model from storage (missing file)."""
    monkeypatch.setenv('TRANSFORMERS_CACHE', str(tmpdir))
    importlib.reload(huggingface)

    # Load is supposed to test direcotry first and than fallnack to cache
    # Exception should always be from not found in cache first
    with pytest.raises(FileNotFoundError, match='Not in cache'):
        huggingface.load(mock_loader, 'test/id')

def test_load_from_storage_dir_success(monkeypatch, mock_loader, tmpdir):
    """Test low-level loading a huggingface model from storage (success)."""
    monkeypatch.setenv('TRANSFORMERS_CACHE', str(tmpdir))
    importlib.reload(huggingface)

    ptr = tmpdir
    for pth in Path('test/id').parts:
        ptr = ptr.mkdir(pth)
    huggingface.load(mock_loader, 'test/id')

def test_load_from_storage_cache_success(monkeypatch, mock_loader, tmpdir):
    """Test low-level loading a huggingface model from storage (success)."""
    monkeypatch.setenv('TRANSFORMERS_CACHE', str(tmpdir))
    importlib.reload(huggingface)

    tmpdir.mkdir('models--test--id')
    huggingface.load(mock_loader, 'test/id')

# @pytest.mark.django_db
# def test_load_ocr_model_test(monkeypatch):
#     """Test load box model. Success"""
#     model_id = 'easyocr'
#     res = {
#         'ved_model': 'mocked_ved',
#         'tokenizer': 'mocked_tokenizer',
#         'image_processor': 'mocked_image_processor',
#     }
#     monkeypatch.setattr(ocr, 'load_hugginface_model', lambda *args, **kwargs: res)

#     # Needed to make sure that changes doen by `load_ocr_model` are not persisted
#     for key in ocr_globals:
#         monkeypatch.setattr(ocr, key, None)

#     assert m.OCRModel.objects.count() == 0
#     ocr.load_ocr_model(model_id)
#     assert m.OCRModel.objects.count() == 1

#     assert ocr.OBJ_MODEL_ID == model_id
#     # Check that the mocked function was called and that globals were set by loader
#     assert ocr.OCR_MODEL == 'mocked_ved'
#     assert ocr.OCR_TOKENIZER == 'mocked_tokenizer'
#     assert ocr.OCR_IMAGE_PROCESSOR == 'mocked_image_processor'

# def test_unload_ocr_model_cpu(monkeypatch, mock_called):
#     """Test unload box model with cpu."""
#     monkeypatch.setattr(ocr.torch.cuda, 'empty_cache', mock_called)
#     monkeypatch.setattr(ocr, 'dev', 'cpu')

#     ocr.unload_ocr_model()
#     assert not hasattr(mock_called, 'called')

# def test_unload_ocr_model_cuda(monkeypatch, mock_called):
#     """Test unload box model with cuda."""
#     monkeypatch.setattr(ocr.torch.cuda, 'empty_cache', mock_called)
#     monkeypatch.setattr(ocr, 'dev', 'cuda')

#     ocr.unload_ocr_model()
#     assert hasattr(mock_called, 'called')

# def test_pipeline_invalide_image():
#     """Test ocr pipeline with invalid image."""
#     with pytest.raises(TypeError, match=r'^img should be PIL Image.*'):
#         ocr._ocr('invalid_image', 'ja') # pylint: disable=protected-access

# def test_pipeline_hugginface(image_pillow, mock_ocr_preprocessor, mock_ocr_tokenizer, mock_ocr_model, monkeypatch):
#     """Test ocr pipeline with hugginface model."""
#     model_id = 'test_model'
#     lang = 'ja'

#     monkeypatch.setattr(ocr, 'OCR_IMAGE_PROCESSOR', mock_ocr_preprocessor(model_id))
#     monkeypatch.setattr(ocr, 'OCR_TOKENIZER', mock_ocr_tokenizer(model_id))
#     monkeypatch.setattr(ocr, 'OCR_MODEL', mock_ocr_model(model_id))

#     res = ocr._ocr(image_pillow, lang) # pylint: disable=protected-access

#     assert res == 'abcde'

# def test_pipeline_hugginface_cuda(image_pillow, mock_ocr_preprocessor, mock_ocr_tokenizer, mock_ocr_model, monkeypatch):
#     """Test ocr pipeline with hugginface model and cuda."""
#     model_id = 'test_model'
#     lang = 'ja'

#     monkeypatch.setattr(ocr, 'dev', 'cuda')
#     monkeypatch.setattr(ocr, 'OCR_IMAGE_PROCESSOR', mock_ocr_preprocessor(model_id))
#     monkeypatch.setattr(ocr, 'OCR_TOKENIZER', mock_ocr_tokenizer(model_id))
#     monkeypatch.setattr(ocr, 'OCR_MODEL', mock_ocr_model(model_id))

#     res = ocr._ocr(image_pillow, lang) # pylint: disable=protected-access

#     assert res == 'abcde'

# def test_queue_placer_handler(monkeypatch, mock_called):
#     """Test queue_placer is setting _ocr as handler, and that it is called."""
#     monkeypatch.setattr(ocr, '_ocr', mock_called)
#     monkeypatch.setattr(ocr.q.msg_queue, 'reuse_msg', False)
#     ocr.ocr(id_=1, block=True)
#     assert hasattr(mock_called, 'called')

# @pytest.mark.parametrize('mock_called', ['test_return'], indirect=True)
# def test_queue_placer_blocking(monkeypatch, mock_called):
#     """Test queue_placer with blocking"""
#     monkeypatch.setattr(ocr, '_ocr', mock_called)
#     monkeypatch.setattr(ocr.q.msg_queue, 'reuse_msg', False)
#     res = ocr.ocr(id_=1, block=True)
#     assert hasattr(mock_called, 'called')
#     assert res == mock_called.expected

# @pytest.mark.parametrize('mock_called', ['test_return'], indirect=True)
# def test_queue_placer_nonblocking(monkeypatch, mock_called):
#     """Test queue_placer with blocking"""
#     monkeypatch.setattr(ocr, '_ocr', mock_called)
#     monkeypatch.setattr(ocr.q.msg_queue, 'reuse_msg', False)
#     ocr.q.stop_workers()
#     res = ocr.ocr(id_=1, block=False)
#     assert isinstance(res, Message)

#     assert not hasattr(mock_called, 'called') # Before resolving the message the handler is not called
#     ocr.q.start_workers()
#     assert res.response() == mock_called.expected
#     assert hasattr(mock_called, 'called') # After resolving the message the handler is called

# def test_pipeline_worker():
#     """Test tsl pipeline with worker"""
#     placeholder = 'placeholder'
#     ocr.q.stop_workers()

#     messages = [ocr.ocr(placeholder, 'ja', 'en', id_=i, block=False) for i in range(3)]
#     assert all(isinstance(_, Message) for _ in messages)
#     def gen():
#         while not ocr.q.msg_queue.empty():
#             yield ocr.q.msg_queue.get()
#     res = list(gen())
#     assert len(res) == len(messages)

####################################################################################
# def test_get_mnt_wrong_options():
#     """Test get_mnt with wrong options."""
#     with pytest.raises(ValueError, match=r'^min_max_new_tokens must be less than max_max_new_tokens$'):
#         tsl.get_mnt(10, {'min_max_new_tokens': 20, 'max_max_new_tokens': 10})

# @pytest.mark.django_db
# def test_load_tsl_model_test(monkeypatch):
#     """Test load box model. Success"""
#     model_id = 'test/id'
#     res = {
#         'seq2seq': 'mocked_seq2seq',
#         'tokenizer': 'mocked_tokenizer',
#     }
#     monkeypatch.setattr(tsl, 'load_hugginface_model', lambda *args, **kwargs: res)

#     # Needed to make sure that changes doen by `load_tsl_model` are not persisted
#     for key in tsl_globals:
#         monkeypatch.setattr(tsl, key, None)

#     assert m.TSLModel.objects.count() == 0
#     tsl.load_tsl_model(model_id)
#     assert m.TSLModel.objects.count() == 1

#     assert tsl.TSL_MODEL_ID == model_id
#     # Check that the mocked function was called and that globals were set by loader
#     assert tsl.TSL_MODEL == 'mocked_seq2seq'
#     assert tsl.TSL_TOKENIZER == 'mocked_tokenizer'

# def test_unload_tsl_model_cpu(monkeypatch, mock_called):
#     """Test unload box model with cpu."""
#     monkeypatch.setattr(tsl.torch.cuda, 'empty_cache', mock_called)
#     monkeypatch.setattr(tsl, 'dev', 'cpu')

#     tsl.unload_tsl_model()
#     assert not hasattr(mock_called, 'called')

# def test_unload_tsl_model_cuda(monkeypatch, mock_called):
#     """Test unload box model with cuda."""
#     monkeypatch.setattr(tsl.torch.cuda, 'empty_cache', mock_called)
#     monkeypatch.setattr(tsl, 'dev', 'cuda')

#     tsl.unload_tsl_model()
#     assert hasattr(mock_called, 'called')

# def test_pipeline_wrong_type(monkeypatch, mock_tsl_tokenizer):
#     """Test tsl pipeline with wrong type."""
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer('test/id'))
#     with pytest.raises(TypeError, match=r'^Unsupported type for text:.*'):
#         tsl._tsl_pipeline(1, 'ja', 'en') # pylint: disable=protected-access

# def test_pipeline_no_tokens(monkeypatch, mock_tsl_tokenizer):
#     """Test tsl pipeline with no tokens generated from pre_tokenize."""
#     monkeypatch.setattr(tsl, 'pre_tokenize', lambda *args, **kwargs: [])
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer('test/id'))

#     res = tsl._tsl_pipeline('', 'ja', 'en') # pylint: disable=protected-access

#     assert res == ''

# def test_pipeline_m2m(monkeypatch, mock_tsl_tokenizer, mock_tsl_model):
#     """Test tsl pipeline with m2m model."""
#     model_id = 'test/id'
#     monkeypatch.setattr(tsl, 'M2M100Tokenizer', mock_tsl_tokenizer)
#     monkeypatch.setattr(tsl, 'TSL_MODEL', mock_tsl_model(model_id))
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer(model_id))

#     tsl._tsl_pipeline('', 'ja', 'en') # pylint: disable=protected-access

#     assert tsl.TSL_TOKENIZER.called_get_lang_id is True


# def test_pipeline(string, monkeypatch, mock_tsl_tokenizer, mock_tsl_model, mock_called):
#     """Test tsl pipeline (also check that cache is not cleared in CPU mode)."""
#     model_id = 'test_model'
#     lang_src = 'ja'
#     lang_dst = 'en'

#     monkeypatch.setattr(tsl, 'TSL_MODEL', mock_tsl_model(model_id))
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer(model_id))
#     monkeypatch.setattr(tsl.torch.cuda, 'empty_cache', mock_called)
#     monkeypatch.setattr(tsl, 'dev', 'cpu')

#     res = tsl._tsl_pipeline(string, lang_src, lang_dst) # pylint: disable=protected-access

#     assert res == string.replace('\n', ' ')
#     assert tsl.TSL_TOKENIZER.model_id == model_id
#     assert tsl.TSL_TOKENIZER.src_lang == lang_src

#     assert not hasattr(mock_called, 'called')

# def test_pipeline_clear_cache(monkeypatch, mock_tsl_tokenizer, mock_tsl_model, mock_called):
#     """Test tsl pipeline with cuda should clear_cache."""
#     model_id = 'test_model'
#     lang_src = 'ja'
#     lang_dst = 'en'

#     monkeypatch.setattr(tsl, 'TSL_MODEL', mock_tsl_model(model_id))
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer(model_id))
#     monkeypatch.setattr(tsl.torch.cuda, 'empty_cache', mock_called)
#     monkeypatch.setattr(tsl, 'dev', 'cuda')

#     tsl._tsl_pipeline('test', lang_src, lang_dst) # pylint: disable=protected-access

#     assert hasattr(mock_called, 'called')



# def test_pipeline_batch(batch_string, monkeypatch, mock_tsl_tokenizer, mock_tsl_model):
#     """Test tsl pipeline with batched string."""
#     model_id = 'test_model'
#     lang_src = 'ja'
#     lang_dst = 'en'

#     monkeypatch.setattr(tsl, 'TSL_MODEL', mock_tsl_model(model_id))
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer(model_id))

#     res = tsl._tsl_pipeline(batch_string, lang_src, lang_dst) # pylint: disable=protected-access

#     assert res == [_.replace('\n', ' ') for _ in batch_string]
#     assert tsl.TSL_TOKENIZER.model_id == model_id
#     assert tsl.TSL_TOKENIZER.src_lang == lang_src

# @pytest.mark.parametrize(
#     'options',
#     [
#         {},
#         {'min_max_new_tokens': 30},
#         {'max_max_new_tokens': 22},
#         {'max_new_tokens': 15},
#         {'max_new_tokens_ratio': 2}
#     ],
#     ids=[
#         'default',
#         'min_max_new_tokens',
#         'max_max_new_tokens',
#         'max_new_tokens',
#         'max_new_tokens_ratio'
#     ]
# )
# def test_pipeline_options(options, string, monkeypatch, mock_tsl_tokenizer, mock_tsl_model):
#     """Test tsl pipeline with options."""
#     model_id = 'test_model'
#     lang_src = 'ja'
#     lang_dst = 'en'

#     monkeypatch.setattr(tsl, 'TSL_MODEL', mock_tsl_model(model_id))
#     monkeypatch.setattr(tsl, 'TSL_TOKENIZER', mock_tsl_tokenizer(model_id))

#     min_max_new_tokens = options.get('min_max_new_tokens', 20)
#     max_max_new_tokens = options.get('max_max_new_tokens', 512)
#     ntok = string.replace('\n', ' ').count(' ') + 1

#     if min_max_new_tokens > max_max_new_tokens:
#         with pytest.raises(ValueError):
#             tsl._tsl_pipeline(string, lang_src, lang_dst, options=options) # pylint: disable=protected-access
#     else:
#         tsl._tsl_pipeline(string, lang_src, lang_dst, options=options) # pylint: disable=protected-access

#     mnt = tsl.get_mnt(ntok, options)

#     model = tsl.TSL_MODEL

#     assert model.options['max_new_tokens'] == mnt

# def test_queue_placer_handler(monkeypatch, mock_called):
#     """Test queue_placer is setting _tsl_pipeline as handler, and that it is called."""
#     monkeypatch.setattr(tsl, '_tsl_pipeline', mock_called)
#     monkeypatch.setattr(tsl.q.msg_queue, 'reuse_msg', False)
#     tsl.tsl_pipeline(id_=1, block=True)
#     assert hasattr(mock_called, 'called')

# @pytest.mark.parametrize('mock_called', ['test_return'], indirect=True)
# def test_queue_placer_blocking(monkeypatch, mock_called):
#     """Test queue_placer with blocking"""
#     monkeypatch.setattr(tsl, '_tsl_pipeline', mock_called)
#     monkeypatch.setattr(tsl.q.msg_queue, 'reuse_msg', False)
#     res = tsl.tsl_pipeline(id_=1, block=True)
#     assert hasattr(mock_called, 'called')
#     assert res == mock_called.expected

# @pytest.mark.parametrize('mock_called', ['test_return'], indirect=True)
# def test_queue_placer_nonblocking(monkeypatch, mock_called):
#     """Test queue_placer with blocking"""
#     monkeypatch.setattr(tsl, '_tsl_pipeline', mock_called)
#     monkeypatch.setattr(tsl.q.msg_queue, 'reuse_msg', False)
#     tsl.q.stop_workers()
#     res = tsl.tsl_pipeline(id_=1, block=False)
#     assert isinstance(res, Message)

#     assert not hasattr(mock_called, 'called') # Before resolving the message the handler is not called
#     tsl.q.start_workers()
#     assert res.response() == mock_called.expected
#     assert hasattr(mock_called, 'called') # After resolving the message the handler is called


# def test_pipeline_worker():
#     """Test tsl pipeline with worker"""
#     placeholder = 'placeholder'
#     tsl.q.stop_workers()

#     messages = [tsl.tsl_pipeline(placeholder, 'ja', 'en', id_=i, batch_id=0, block=False) for i in range(3)]
#     assert all(isinstance(_, Message) for _ in messages)
#     # Makes sure that batching is enabled for tsl queue (retrieve all messages withone `get` call)
#     res = tsl.q.get()
#     assert len(res) == len(messages)


def test_load_hugginface_model_invalide_type():
    """Test high-level loading a huggingface model. Request unkown entity."""
    with pytest.raises(ValueError, match=r'^Unknown request: .*'):
        huggingface.load_hugginface_model('test', ['invalid'])

def test_load_hugginface_model_return_none(monkeypatch):
    """Test high-level loading a huggingface model. Return None from load."""
    def mock_load(*args):
        """Mocked load function."""
        return None
    monkeypatch.setattr(huggingface, 'load', mock_load)

    with pytest.raises(ValueError, match=r'^Could not load model: .*'):
        huggingface.load_hugginface_model('test', ['model'])


@pytest.mark.parametrize('model_type', [
    'tokenizer',
    'ved_model',
    'model',
    'image_processor',
    'seq2seq'
])
def test_load_hugginface_model_success(monkeypatch, model_type):
    """Test high-level loading a huggingface model."""
    def mock_load(loader, *args):
        """Mocked load function."""
        assert loader == huggingface.mapping[model_type]
        class App():
            """Mocked huggingface class with `to` method."""
            def to(self, x): # pylint: disable=invalid-name,unused-argument
                """Mocked method."""
                return None
        return App()
    monkeypatch.setattr(huggingface, 'load', mock_load)

    loaded = huggingface.load_hugginface_model('test', [model_type])

    assert isinstance(loaded, dict)
    assert len(loaded) == 1
    assert model_type in loaded
